{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import isnan\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def importFile(file_path):\n",
    "\n",
    "    #TODO : ability to set other parameters when loading data through constructor\n",
    "    \n",
    "    if file_path.endswith('.csv') or file_path.endswith('.txt'):\n",
    "        with open(file_path, 'r') as f:\n",
    "            first_line = f.readline()\n",
    "        if '\\t' in first_line:\n",
    "            return pd.read_csv(file_path, sep='\\t')\n",
    "        elif ';' in first_line:\n",
    "            return pd.read_csv(file_path, sep=',')\n",
    "        elif ',' in first_line:\n",
    "            return pd.read_csv(file_path, sep=',')\n",
    "        else:\n",
    "            return pd.read_fwf(file_path)\n",
    "\n",
    "    elif file_path.endswith('.json'):\n",
    "        with open(file_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "        sheets = excel_file.sheet_names\n",
    "        number_of_sheets = len(sheets)\n",
    "        print(f'found {number_of_sheets} sheets ')\n",
    "        if number_of_sheets == 1:\n",
    "            return pd.read_excel(file_path, sheet_name=sheets[0])\n",
    "        else:\n",
    "            df = []\n",
    "            for i in range(number_of_sheets):\n",
    "                df.append(pd.read_excel(file_path, sheet_name=sheets[i]))\n",
    "            return df \n",
    "\n",
    "    # TODO connecting to database and load sql tables in dataframe\n",
    "    elif file_path.endswith('.sql'):\n",
    "        return pd.read_sql(file_path)\n",
    "\n",
    "    else:\n",
    "        # TODO return a message such that it doesn't abruptly stop the program (error handling)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = importFile('./datasets/MarketSegmentation_Train.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience    829\n",
       "Spending_Score       0\n",
       "Family_Size        335\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with null values\n",
    "df = df.dropna(how='all') \n",
    "# reset the index of a pandas dataframe to default sequential values starting from 0.\n",
    "# drop = True means that the old index is dropped and not included as a new column in the dataframe.\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Work_Experience', 'Family_Size'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df1 = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = df.select_dtypes(include=np.number).columns\n",
    "mapping = dict()\n",
    "for feature in df.columns:\n",
    "    if feature not in cols_num:\n",
    "        # create label mapping for categorical feature values\n",
    "        mappings = {k: i for i, k in enumerate(df1[feature])}\n",
    "        mapping[feature] = mappings\n",
    "        df1[feature] = df1[feature].map(mapping[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': {'Male': 8067, 'Female': 8066},\n",
       " 'Ever_Married': {'No': 8066, 'Yes': 8067, nan: 8044},\n",
       " 'Graduated': {'No': 8064, 'Yes': 8067, nan: 7995},\n",
       " 'Profession': {'Healthcare': 8066,\n",
       "  'Engineer': 8048,\n",
       "  'Lawyer': 8057,\n",
       "  'Entertainment': 8058,\n",
       "  'Artist': 8062,\n",
       "  'Executive': 8067,\n",
       "  'Doctor': 8047,\n",
       "  'Homemaker': 8056,\n",
       "  'Marketing': 8026,\n",
       "  nan: 8063},\n",
       " 'Spending_Score': {'Low': 8066, 'Average': 8067, 'High': 8062},\n",
       " 'Var_1': {'Cat_4': 8067,\n",
       "  'Cat_6': 8066,\n",
       "  'Cat_7': 8020,\n",
       "  'Cat_3': 8058,\n",
       "  'Cat_1': 8063,\n",
       "  'Cat_2': 8053,\n",
       "  nan: 7991,\n",
       "  'Cat_5': 7967},\n",
       " 'Segmentation': {'D': 8065, 'A': 8060, 'B': 8067, 'C': 8061}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Male': 8067, 'Female': 8066}\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for i, k in enumerate(df1['Gender']):\n",
    "    mapping[k] = i   #mappings['Male'] = 1...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Male': 8067, 'Female': 8066}\n"
     ]
    }
   ],
   "source": [
    "print({ k : i for i, k in enumerate(df['Gender']) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cols_num:    \n",
    "\n",
    "    # dataframe of rows that have na values for that feature. All the rows containig na values for other features are dropped.\n",
    "    test_df = df1[df1[feature].isnull()==True].dropna(subset=[x for x in df1.columns if x != feature])\n",
    "\n",
    "    # dataframe of rows that do not have na values for that feature. All the rows containig na values for other features are dropped.\n",
    "    train_df = df1[df1[feature].isnull()==False].dropna(subset=[x for x in df1.columns if x != feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ask if want to convert categorical to numerical\n",
    "# categorical to numerical\n",
    "df[\"Gender\"] = df[\"Gender\"].astype(\"category\")\n",
    "df[\"Gender_encoded\"] = df[\"Gender\"].cat.codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_16060\\3977765826.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                 463479.214551\n",
       "Age                    43.466906\n",
       "Work_Experience         2.641663\n",
       "Family_Size             2.850123\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean imputation\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_16060\\530051474.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.median()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                 463472.5\n",
       "Age                    40.0\n",
       "Work_Experience         1.0\n",
       "Family_Size             3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 458982\n",
       "Gender               Male\n",
       "Ever_Married          Yes\n",
       "Age                  35.0\n",
       "Graduated             Yes\n",
       "Profession         Artist\n",
       "Work_Experience       1.0\n",
       "Spending_Score        Low\n",
       "Family_Size           2.0\n",
       "Var_1               Cat_6\n",
       "Segmentation            D\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fit the imputer to the data and transform it\n",
    "df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)\n",
    "df_median_imputed = pd.DataFrame(median_imputer.fit_transform(df), columns=df.columns)\n",
    "df_most_frequent_imputed = pd.DataFrame(most_frequent_imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnimputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = pd.DataFrame(knnimputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Load the data set\n",
    "# df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# # Create the rescaler object\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Fit the rescaler to the data and transform it\n",
    "# df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0398511a9cde84ab83a2fa188ff6508a33d7c0397b3581839dbbf3238a247df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
