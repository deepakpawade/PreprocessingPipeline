{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import isnan\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def importFile(file_path):\n",
    "\n",
    "    #TODO : ability to set other parameters when loading data through constructor\n",
    "    \n",
    "    if file_path.endswith('.csv') or file_path.endswith('.txt'):\n",
    "        with open(file_path, 'r') as f:\n",
    "            first_line = f.readline()\n",
    "        if '\\t' in first_line:\n",
    "            return pd.read_csv(file_path, sep='\\t')\n",
    "        elif ';' in first_line:\n",
    "            return pd.read_csv(file_path, sep=',')\n",
    "        elif ',' in first_line:\n",
    "            return pd.read_csv(file_path, sep=',')\n",
    "        else:\n",
    "            return pd.read_fwf(file_path)\n",
    "\n",
    "    elif file_path.endswith('.json'):\n",
    "        with open(file_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "        sheets = excel_file.sheet_names\n",
    "        number_of_sheets = len(sheets)\n",
    "        print(f'found {number_of_sheets} sheets ')\n",
    "        if number_of_sheets == 1:\n",
    "            return pd.read_excel(file_path, sheet_name=sheets[0])\n",
    "        else:\n",
    "            df = []\n",
    "            for i in range(number_of_sheets):\n",
    "                df.append(pd.read_excel(file_path, sheet_name=sheets[i]))\n",
    "            return df \n",
    "\n",
    "    # TODO connecting to database and load sql tables in dataframe\n",
    "    elif file_path.endswith('.sql'):\n",
    "        return pd.read_sql(file_path)\n",
    "\n",
    "    else:\n",
    "        # TODO return a message such that it doesn't abruptly stop the program (error handling)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = importFile('./datasets/MarketSegmentation_Train.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience    829\n",
       "Spending_Score       0\n",
       "Family_Size        335\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with null values\n",
    "df = df.dropna(how='all') \n",
    "# reset the index of a pandas dataframe to default sequential values starting from 0.\n",
    "# drop = True means that the old index is dropped and not included as a new column in the dataframe.\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ever_Married', 'Graduated', 'Profession', 'Work_Experience',\n",
       "       'Family_Size', 'Var_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.dropna()['Work_Experience'] % 1 == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def int_checker(df,df1,cols):\n",
    "    for col in cols:\n",
    "        # remove na values in original and check if all values have 0 decimal.\n",
    "        if (df.dropna()[col] % 1 == 0).all():\n",
    "    # if all values are integers, convert the column to int64 data type\n",
    "            df1[col] = df1[col].round()\n",
    "            df1[col] = df1[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df1, type=\"both\", method_num=\"KNNImputer\", method_cat=\"most_frequent\"):\n",
    "    df = copy.deepcopy(df1)\n",
    "\n",
    "    num_cols = df.select_dtypes(include=np.number).columns\n",
    "    cat_cols = df.select_dtypes(include=object).columns\n",
    "    missing_num = missing_cat = 0\n",
    "\n",
    "    if type == \"both\":\n",
    "        mask = df.isnull().any()\n",
    "        missing_num = missing_cat = 1\n",
    "    elif type == \"categorical\":\n",
    "        missing_cat = 1\n",
    "        mask = df.dtypes == object\n",
    "    elif type == \"numerical\":\n",
    "        missing_num = 1\n",
    "        mask = df.dtypes != object\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for type_of_feature\")\n",
    "        \n",
    "# TODO multivariate imputation\n",
    "    if missing_num:\n",
    "        if method_num == 'KNNImputer':\n",
    "            # TODO n neighbours\n",
    "            imputer = KNNImputer()\n",
    "            df[num_cols] = pd.DataFrame(imputer.fit_transform(\n",
    "                copy.deepcopy(df[num_cols])), columns=num_cols)\n",
    "            int_checker(df1, df, num_cols)\n",
    "\n",
    "        elif method_num in ['mean', 'median', 'most_frequent']:\n",
    "            imputer = SimpleImputer(strategy=method_num)\n",
    "            df[num_cols] = pd.DataFrame(imputer.fit_transform(\n",
    "                copy.deepcopy(df[num_cols])), columns=num_cols)\n",
    "            int_checker(df1, df, num_cols)\n",
    "\n",
    "        elif method_num == \"IterativeImputer\":\n",
    "            imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "            df[num_cols] = pd.DataFrame(imputer.fit_transform(\n",
    "                copy.deepcopy(df[num_cols])), columns=num_cols)\n",
    "            int_checker(df1, df, num_cols)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if missing_cat:\n",
    "        if method_cat == 'KNNImputer':\n",
    "            pass\n",
    "        elif method_cat in ['most_frequent']:\n",
    "            imputer = SimpleImputer(strategy=method_cat)\n",
    "            df[cat_cols] = pd.DataFrame(imputer.fit_transform(\n",
    "                copy.deepcopy(df[cat_cols])), columns=cat_cols)\n",
    "        else:\n",
    "            pass\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = missing_values(df,\"both\",)\n",
    "df1.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>Average</td>\n",
       "      <td>3</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>464018</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>7</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>464685</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>465406</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>467299</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>461879</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0     462809    Male           No   22        No     Healthcare   \n",
       "1     462643  Female          Yes   38       Yes       Engineer   \n",
       "2     466315  Female          Yes   67       Yes       Engineer   \n",
       "3     461735    Male          Yes   67       Yes         Lawyer   \n",
       "4     462669  Female          Yes   40       Yes  Entertainment   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "8063  464018    Male           No   22        No         Artist   \n",
       "8064  464685    Male           No   35        No      Executive   \n",
       "8065  465406  Female           No   33       Yes     Healthcare   \n",
       "8066  467299  Female           No   27       Yes     Healthcare   \n",
       "8067  461879    Male          Yes   37       Yes      Executive   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0                   1            Low            4  Cat_4            D  \n",
       "1                   3        Average            3  Cat_4            A  \n",
       "2                   1            Low            1  Cat_6            B  \n",
       "3                   0           High            2  Cat_6            B  \n",
       "4                   3           High            6  Cat_6            A  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "8063                0            Low            7  Cat_1            D  \n",
       "8064                3            Low            4  Cat_4            D  \n",
       "8065                1            Low            1  Cat_6            D  \n",
       "8066                1            Low            4  Cat_6            B  \n",
       "8067                0        Average            3  Cat_4            B  \n",
       "\n",
       "[8068 rows x 11 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Work_Experience', 'Family_Size'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df1 = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regression_impute(df, model):\n",
    "        # function for predicting missing values with linear regression\n",
    "\n",
    "        #  gets a list of all the column names that contain numerical data in the DataFrame.\n",
    "        cols_num = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "        #  empty dictionary mapping to store the mapping between categorical feature values and their numerical representations.\n",
    "        mapping = dict()\n",
    "\n",
    "        for feature in df.columns:\n",
    "            if feature not in cols_num:\n",
    "\n",
    "                # create label mapping for categorical feature values\n",
    "                # this line creates a dictionary mappings that maps each\n",
    "                #  unique value in the column to a unique integer representation, using the enumerate function.\n",
    "                    # mapping = {}\n",
    "                    # for i, k in enumerate(df1['Gender']):\n",
    "                    #   mapping[k] = i\n",
    "                mappings = {k: i for i, k in enumerate(df[feature])} \n",
    "                mapping[feature] = mappings\n",
    "\n",
    "                # maps the dictionary to that feature column\n",
    "                df[feature] = df[feature].map(mapping[feature])\n",
    "\n",
    "                # this is also converting nan values to numbers which is handleled by knn assuming\n",
    "\n",
    "        for feature in cols_num: \n",
    "                try:\n",
    "\n",
    "                     # dataframe of rows that have na values for that feature. All the rows containig na values for other features are dropped.\n",
    "                    test_df = df[df[feature].isnull()==True].dropna(subset=[x for x in df.columns if x != feature])\n",
    "\n",
    "                    # dataframe of rows that do not have na values for that feature. All the rows containig na values for other features are dropped.\n",
    "                    train_df = df[df[feature].isnull()==False].dropna(subset=[x for x in df.columns if x != feature])\n",
    "                    if len(test_df.index) != 0:\n",
    "\n",
    "                        # assuming its making a sequence of things to do. Here, its fitting to the dataframe.\n",
    "                        # StandardScaler will standardize the independent variables (mean = 0, SD = 1) but does not change skewness of the data i.e make it gaussian\n",
    "                        # Its often not necessary to make independent variables into gaussian distribution but may benefit in some cases,\n",
    "                        pipe = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "                        # applying log tranformation to target variable to make it gaussian distribution\n",
    "                        y = np.log(train_df[feature]) # log-transform the data\n",
    "                        X_train = train_df.drop(feature, axis=1)\n",
    "                        test_df.drop(feature, axis=1, inplace=True)\n",
    "                        \n",
    "                        try:\n",
    "                            model = pipe.fit(X_train, y)  #might return error because logarithm of zero or negative values is undefined\n",
    "                        except:\n",
    "                            y = train_df[feature] # use non-log-transformed data\n",
    "                            model = pipe.fit(X_train, y)\n",
    "\n",
    "                         #  checks if the target variable used for fitting the model is the non-log-transformed one or not. If the target variable is non-log-transformed, then the code will proceed to the next step.\n",
    "                        if (y == train_df[feature]).all(): \n",
    "                            pred = model.predict(test_df)\n",
    "                        else:\n",
    "                            # If the target variable used for fitting the model is the log-transformed one, then the predictions are exponentiated to get back the original target variable values.\n",
    "                            pred = np.exp(model.predict(test_df)) # predict values\n",
    "\n",
    "                        test_df[feature]= pred\n",
    "\n",
    "#  checks if all the values in the target variable, after replacing the missing values with -9999, are evenly divisible by 1. \n",
    "# If this condition is true, it means that all the values are integers, and if it's false, it means that at least one of the values is a floating-point number. \n",
    "# The .all() method at the end checks if the condition is true for all the values in the target variable.\n",
    "# -9999 is a value that is highly unlikely to appear in the original data\n",
    "                        if (df[feature].fillna(-9999) % 1  == 0).all(): # checks if the original target variable was an integer\n",
    "                            # round back to INTs, if original data were INTs\n",
    "                            test_df[feature] = test_df[feature].round()\n",
    "                            test_df[feature] = test_df[feature].astype('Int64')\n",
    "                            df[feature].update(test_df[feature])                          \n",
    "                        else:\n",
    "                            df[feature].update(test_df[feature])  \n",
    "                        print(f'LINREG imputation of {len(pred)} value(s) succeeded for feature \"{feature}\"')\n",
    "                except:\n",
    "                    print(f'LINREG imputation failed for feature \"{feature}\"', )\n",
    "        for feature in df.columns: \n",
    "            try:   \n",
    "                # map categorical feature values back to original\n",
    "# mappings_i = {}\n",
    "# for k, v in  mapping['Profession'].items():\n",
    "#     mappings_i[v] = k\n",
    "# mappings_i\n",
    "# {8066: 'Healthcare',\n",
    "#  8048: 'Engineer',\n",
    "#  8057: 'Lawyer',..}\n",
    "\n",
    "                mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
    "                df[feature] = df[feature].map(mappings_inv)\n",
    "            except:\n",
    "                pass\n",
    "        return df\n",
    "\n",
    "def impute( df, imputer, type):\n",
    "        # function for imputing missing values in the data\n",
    "        cols_num = df.select_dtypes(include=np.number).columns \n",
    "\n",
    "        if type == 'num':\n",
    "            # numerical features\n",
    "            for feature in df.columns: \n",
    "                if feature in cols_num:\n",
    "                    if df[feature].isna().sum().sum() != 0:\n",
    "                        try:\n",
    "                            df_imputed = pd.DataFrame(imputer.fit_transform(np.array(df[feature]).reshape(-1, 1)))\n",
    "                            counter = df[feature].isna().sum().sum() - df_imputed.isna().sum().sum()\n",
    "\n",
    "                            if (df[feature].fillna(-9999) % 1  == 0).all():\n",
    "                                df[feature] = df_imputed\n",
    "                                # round back to INTs, if original data were INTs\n",
    "                                df[feature] = df[feature].round()\n",
    "                                df[feature] = df[feature].astype('Int64')                                        \n",
    "                            else:\n",
    "                                df[feature] = df_imputed\n",
    "                            if counter != 0:\n",
    "                                print(f' imputation of {counter} value(s) succeeded for feature \"{feature}\"' )\n",
    "                        except:\n",
    "                            print(f'imputation failed for feature \"{feature}\"')\n",
    "        else:\n",
    "            # categorical features\n",
    "            for feature in df.columns:\n",
    "                if feature not in cols_num:\n",
    "                    if df[feature].isna().sum()!= 0:\n",
    "                        try:\n",
    "                            mapping = dict()\n",
    "                            mappings = {k: i for i, k in enumerate(df[feature].dropna().unique(), 0)}\n",
    "                            mapping[feature] = mappings\n",
    "                            df[feature] = df[feature].map(mapping[feature])\n",
    "\n",
    "                            df_imputed = pd.DataFrame(imputer.fit_transform(np.array(df[feature]).reshape(-1, 1)), columns=[feature])    \n",
    "                            counter = sum(1 for i, j in zip(list(df_imputed[feature]), list(df[feature])) if i != j)\n",
    "\n",
    "                            # round to integers before mapping back to original values\n",
    "                            df[feature] = df_imputed\n",
    "                            df[feature] = df[feature].round()\n",
    "                            df[feature] = df[feature].astype('Int64')  \n",
    "\n",
    "                            # map values back to original\n",
    "                            mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
    "                            df[feature] = df[feature].map(mappings_inv)\n",
    "                            if counter != 0:\n",
    "                               print(f'imputation of {counter} value(s) succeeded for feature \"{feature}\"' )\n",
    "                        except:\n",
    "                            print(f'imputation failed for feature \"{feature}\"' )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINREG imputation of 764 value(s) succeeded for feature \"Work_Experience\"\n",
      "LINREG imputation of 270 value(s) succeeded for feature \"Family_Size\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepdesk\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "df2 = lin_regression_impute(copy.deepcopy(df), lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience     65\n",
       "Spending_Score       0\n",
       "Family_Size         65\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>459576</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>85</td>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>467426</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86</td>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>465638</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>461233</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>459453</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>88</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>459620</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>459783</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18</td>\n",
       "      <td>No</td>\n",
       "      <td>Artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>459057</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>68</td>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>462779</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>61</td>\n",
       "      <td>No</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>460637</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>19</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "186   459576  Female          Yes   85        No         Lawyer   \n",
       "352   467426  Female          Yes   86        No         Lawyer   \n",
       "652   465638  Female          Yes   51       Yes         Artist   \n",
       "766   461233    Male          Yes   37       Yes  Entertainment   \n",
       "943   459453    Male          Yes   88       Yes         Lawyer   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "7440  459620  Female          Yes   29        No      Marketing   \n",
       "7493  459783  Female          Yes   18        No         Artist   \n",
       "7530  459057    Male          Yes   68        No         Lawyer   \n",
       "7607  462779  Female          Yes   61        No      Marketing   \n",
       "7655  460637  Female           No   19        No     Healthcare   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "186               NaN            Low          NaN    NaN            A  \n",
       "352               NaN            Low          NaN  Cat_6            B  \n",
       "652               NaN            Low          NaN  Cat_3            C  \n",
       "766               NaN            Low          NaN  Cat_3            D  \n",
       "943               NaN            Low          NaN  Cat_6            B  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "7440              NaN            Low          NaN    NaN            D  \n",
       "7493              NaN           High          NaN  Cat_1            B  \n",
       "7530              NaN           High          NaN  Cat_6            D  \n",
       "7607              NaN        Average          NaN  Cat_6            D  \n",
       "7655              NaN            Low          NaN  Cat_3            D  \n",
       "\n",
       "[65 rows x 11 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['Work_Experience'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>459576</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>85</td>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>467426</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86</td>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>465638</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>461233</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>459453</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>88</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>459620</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>459783</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18</td>\n",
       "      <td>No</td>\n",
       "      <td>Artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>459057</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>68</td>\n",
       "      <td>No</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>462779</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>61</td>\n",
       "      <td>No</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>460637</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>19</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "186   459576  Female          Yes   85        No         Lawyer   \n",
       "352   467426  Female          Yes   86        No         Lawyer   \n",
       "652   465638  Female          Yes   51       Yes         Artist   \n",
       "766   461233    Male          Yes   37       Yes  Entertainment   \n",
       "943   459453    Male          Yes   88       Yes         Lawyer   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "7440  459620  Female          Yes   29        No      Marketing   \n",
       "7493  459783  Female          Yes   18        No         Artist   \n",
       "7530  459057    Male          Yes   68        No         Lawyer   \n",
       "7607  462779  Female          Yes   61        No      Marketing   \n",
       "7655  460637  Female           No   19        No     Healthcare   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "186               NaN            Low          NaN    NaN            A  \n",
       "352               NaN            Low          NaN  Cat_6            B  \n",
       "652               NaN            Low          NaN  Cat_3            C  \n",
       "766               NaN            Low          NaN  Cat_3            D  \n",
       "943               NaN            Low          NaN  Cat_6            B  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "7440              NaN            Low          NaN    NaN            D  \n",
       "7493              NaN           High          NaN  Cat_1            B  \n",
       "7530              NaN           High          NaN  Cat_6            D  \n",
       "7607              NaN        Average          NaN  Cat_6            D  \n",
       "7655              NaN            Low          NaN  Cat_3            D  \n",
       "\n",
       "[65 rows x 11 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['Family_Size'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " imputation of 65 value(s) succeeded for feature \"Work_Experience\"\n",
      " imputation of 65 value(s) succeeded for feature \"Family_Size\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df3 = impute( copy.deepcopy(df2), imputer, type='num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience      0\n",
       "Spending_Score       0\n",
       "Family_Size          0\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = df.select_dtypes(include=np.number).columns\n",
    "mapping = dict()\n",
    "for feature in df.columns:\n",
    "    if feature not in cols_num:\n",
    "        # create label mapping for categorical feature values\n",
    "        mappings = {k: i for i, k in enumerate(df1[feature])}\n",
    "        mapping[feature] = mappings\n",
    "        df1[feature] = df1[feature].map(mapping[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': {'Male': 8067, 'Female': 8066},\n",
       " 'Ever_Married': {'No': 8066, 'Yes': 8067, nan: 8044},\n",
       " 'Graduated': {'No': 8064, 'Yes': 8067, nan: 7995},\n",
       " 'Profession': {'Healthcare': 8066,\n",
       "  'Engineer': 8048,\n",
       "  'Lawyer': 8057,\n",
       "  'Entertainment': 8058,\n",
       "  'Artist': 8062,\n",
       "  'Executive': 8067,\n",
       "  'Doctor': 8047,\n",
       "  'Homemaker': 8056,\n",
       "  'Marketing': 8026,\n",
       "  nan: 8063},\n",
       " 'Spending_Score': {'Low': 8066, 'Average': 8067, 'High': 8062},\n",
       " 'Var_1': {'Cat_4': 8067,\n",
       "  'Cat_6': 8066,\n",
       "  'Cat_7': 8020,\n",
       "  'Cat_3': 8058,\n",
       "  'Cat_1': 8063,\n",
       "  'Cat_2': 8053,\n",
       "  nan: 7991,\n",
       "  'Cat_5': 7967},\n",
       " 'Segmentation': {'D': 8065, 'A': 8060, 'B': 8067, 'C': 8061}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>8067</td>\n",
       "      <td>8066</td>\n",
       "      <td>22</td>\n",
       "      <td>8064</td>\n",
       "      <td>8066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8067</td>\n",
       "      <td>8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>8066</td>\n",
       "      <td>8067</td>\n",
       "      <td>38</td>\n",
       "      <td>8067</td>\n",
       "      <td>8048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8067</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8067</td>\n",
       "      <td>8060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>8066</td>\n",
       "      <td>8067</td>\n",
       "      <td>67</td>\n",
       "      <td>8067</td>\n",
       "      <td>8048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>8067</td>\n",
       "      <td>8067</td>\n",
       "      <td>67</td>\n",
       "      <td>8067</td>\n",
       "      <td>8057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8062</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>8066</td>\n",
       "      <td>8067</td>\n",
       "      <td>40</td>\n",
       "      <td>8067</td>\n",
       "      <td>8058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8062</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>8060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>464018</td>\n",
       "      <td>8067</td>\n",
       "      <td>8066</td>\n",
       "      <td>22</td>\n",
       "      <td>8064</td>\n",
       "      <td>8063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8063</td>\n",
       "      <td>8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>464685</td>\n",
       "      <td>8067</td>\n",
       "      <td>8066</td>\n",
       "      <td>35</td>\n",
       "      <td>8064</td>\n",
       "      <td>8067</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8067</td>\n",
       "      <td>8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>465406</td>\n",
       "      <td>8066</td>\n",
       "      <td>8066</td>\n",
       "      <td>33</td>\n",
       "      <td>8067</td>\n",
       "      <td>8066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>467299</td>\n",
       "      <td>8066</td>\n",
       "      <td>8066</td>\n",
       "      <td>27</td>\n",
       "      <td>8067</td>\n",
       "      <td>8066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8066</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>461879</td>\n",
       "      <td>8067</td>\n",
       "      <td>8067</td>\n",
       "      <td>37</td>\n",
       "      <td>8067</td>\n",
       "      <td>8067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8067</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8067</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender  Ever_Married  Age  Graduated  Profession  \\\n",
       "0     462809    8067          8066   22       8064        8066   \n",
       "1     462643    8066          8067   38       8067        8048   \n",
       "2     466315    8066          8067   67       8067        8048   \n",
       "3     461735    8067          8067   67       8067        8057   \n",
       "4     462669    8066          8067   40       8067        8058   \n",
       "...      ...     ...           ...  ...        ...         ...   \n",
       "8063  464018    8067          8066   22       8064        8063   \n",
       "8064  464685    8067          8066   35       8064        8067   \n",
       "8065  465406    8066          8066   33       8067        8066   \n",
       "8066  467299    8066          8066   27       8067        8066   \n",
       "8067  461879    8067          8067   37       8067        8067   \n",
       "\n",
       "      Work_Experience  Spending_Score  Family_Size  Var_1  Segmentation  \n",
       "0                 1.0            8066          4.0   8067          8065  \n",
       "1                 NaN            8067          3.0   8067          8060  \n",
       "2                 1.0            8066          1.0   8066          8067  \n",
       "3                 0.0            8062          2.0   8066          8067  \n",
       "4                 NaN            8062          6.0   8066          8060  \n",
       "...               ...             ...          ...    ...           ...  \n",
       "8063              0.0            8066          7.0   8063          8065  \n",
       "8064              3.0            8066          4.0   8067          8065  \n",
       "8065              1.0            8066          1.0   8066          8065  \n",
       "8066              1.0            8066          4.0   8066          8067  \n",
       "8067              0.0            8067          3.0   8067          8067  \n",
       "\n",
       "[8068 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8066: 'Healthcare',\n",
       " 8048: 'Engineer',\n",
       " 8057: 'Lawyer',\n",
       " 8058: 'Entertainment',\n",
       " 8062: 'Artist',\n",
       " 8067: 'Executive',\n",
       " 8047: 'Doctor',\n",
       " 8056: 'Homemaker',\n",
       " 8026: 'Marketing',\n",
       " 8063: nan}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings_i = {}\n",
    "for k, v in  mapping['Profession'].items():\n",
    "    mappings_i[v] = k\n",
    "mappings_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df1.columns: \n",
    "    try:\n",
    "        # map categorical feature values back to original\n",
    "        mappings_inv = {v: k for k, v in mapping[feature].items()}\n",
    "        df1[feature] = df1[feature].map(mappings_inv)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>464018</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>464685</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>465406</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>467299</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>461879</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0     462809    Male           No   22        No     Healthcare   \n",
       "1     462643  Female          Yes   38       Yes       Engineer   \n",
       "2     466315  Female          Yes   67       Yes       Engineer   \n",
       "3     461735    Male          Yes   67       Yes         Lawyer   \n",
       "4     462669  Female          Yes   40       Yes  Entertainment   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "8063  464018    Male           No   22        No            NaN   \n",
       "8064  464685    Male           No   35        No      Executive   \n",
       "8065  465406  Female           No   33       Yes     Healthcare   \n",
       "8066  467299  Female           No   27       Yes     Healthcare   \n",
       "8067  461879    Male          Yes   37       Yes      Executive   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0                 1.0            Low          4.0  Cat_4            D  \n",
       "1                 NaN        Average          3.0  Cat_4            A  \n",
       "2                 1.0            Low          1.0  Cat_6            B  \n",
       "3                 0.0           High          2.0  Cat_6            B  \n",
       "4                 NaN           High          6.0  Cat_6            A  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "8063              0.0            Low          7.0  Cat_1            D  \n",
       "8064              3.0            Low          4.0  Cat_4            D  \n",
       "8065              1.0            Low          1.0  Cat_6            D  \n",
       "8066              1.0            Low          4.0  Cat_6            B  \n",
       "8067              0.0        Average          3.0  Cat_4            B  \n",
       "\n",
       "[8068 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Male': 8067, 'Female': 8066}\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for i, k in enumerate(df1['Gender']):\n",
    "    mapping[k] = i   #mappings['Male'] = 1...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Male': 8067, 'Female': 8066}\n"
     ]
    }
   ],
   "source": [
    "print({ k : i for i, k in enumerate(df['Gender']) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cols_num:    \n",
    "\n",
    "    # dataframe of rows that have na values for that feature. All the rows containig na values for other features are dropped.\n",
    "    test_df = df1[df1[feature].isnull()==True].dropna(subset=[x for x in df1.columns if x != feature])\n",
    "\n",
    "    # dataframe of rows that do not have na values for that feature. All the rows containig na values for other features are dropped.\n",
    "    train_df = df1[df1[feature].isnull()==False].dropna(subset=[x for x in df1.columns if x != feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ask if want to convert categorical to numerical\n",
    "# categorical to numerical\n",
    "df[\"Gender\"] = df[\"Gender\"].astype(\"category\")\n",
    "df[\"Gender_encoded\"] = df[\"Gender\"].cat.codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_16060\\3977765826.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                 463479.214551\n",
       "Age                    43.466906\n",
       "Work_Experience         2.641663\n",
       "Family_Size             2.850123\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean imputation\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepdesk\\AppData\\Local\\Temp\\ipykernel_16060\\530051474.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.median()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                 463472.5\n",
       "Age                    40.0\n",
       "Work_Experience         1.0\n",
       "Family_Size             3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 458982\n",
       "Gender               Male\n",
       "Ever_Married          Yes\n",
       "Age                  35.0\n",
       "Graduated             Yes\n",
       "Profession         Artist\n",
       "Work_Experience       1.0\n",
       "Spending_Score        Low\n",
       "Family_Size           2.0\n",
       "Var_1               Cat_6\n",
       "Segmentation            D\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fit the imputer to the data and transform it\n",
    "df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)\n",
    "df_median_imputed = pd.DataFrame(median_imputer.fit_transform(df), columns=df.columns)\n",
    "df_most_frequent_imputed = pd.DataFrame(most_frequent_imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnimputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = pd.DataFrame(knnimputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Load the data set\n",
    "# df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# # Create the rescaler object\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Fit the rescaler to the data and transform it\n",
    "# df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0398511a9cde84ab83a2fa188ff6508a33d7c0397b3581839dbbf3238a247df4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
